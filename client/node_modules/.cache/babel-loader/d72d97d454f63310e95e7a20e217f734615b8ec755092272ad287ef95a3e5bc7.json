{"ast":null,"code":"import _regeneratorRuntime from\"C:/Users/farha/OneDrive/Desktop/sak-productivity-suite/client/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";import _asyncToGenerator from\"C:/Users/farha/OneDrive/Desktop/sak-productivity-suite/client/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";import _slicedToArray from\"C:/Users/farha/OneDrive/Desktop/sak-productivity-suite/client/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";/*global chrome*/import React,{useState,useEffect,useRef}from\"react\";import{jsx as _jsx}from\"react/jsx-runtime\";import{Fragment as _Fragment}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";function AudioRetrieval(){var _useState=useState(\"\"),_useState2=_slicedToArray(_useState,2),transcriptTextArea=_useState2[0],setTranscriptTextArea=_useState2[1];var transcriptTextAreaRef=useRef(null);var handleStartCapture=function handleStartCapture(){chrome.tabCapture.capture({audio:true},function(stream){var audioContext=new AudioContext();var mediaStreamSource=audioContext.createMediaStreamSource(stream);mediaStreamSource.connect(audioContext.destination);// Set up the speech recognition object\nvar SpeechRecognition=window.speechRecognition||window.webkitSpeechRecognition;var recognition=new SpeechRecognition();recognition.continuous=true;recognition.interimResults=true;recognition.lang='en-US';recognition.listening=true;recognition.start();// Process the speech recognition results\nrecognition.onresult=function(event){var eventText=\"\";for(var i=0;i<event.results.length;i++){eventText+=event.results[i][0].transcript;}// console.log(eventText);\ntranscriptTextAreaRef.current.value=eventText;};});};var handleSendingToAI=/*#__PURE__*/function(){var _ref=_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee(){var prompt,response,data;return _regeneratorRuntime().wrap(function _callee$(_context){while(1)switch(_context.prev=_context.next){case 0:prompt=\"This is a question asked by a person: \"+\" Answer in a sentence or two. Do not be verbose: \"+transcriptTextAreaRef.current.value;console.log(prompt);_context.prev=2;_context.next=5;return fetch(\"https://sak-productivity-suite.herokuapp.com/use-chatgpt\",{method:\"POST\",headers:{\"Content-Type\":\"application/json\"},body:JSON.stringify({prompt:prompt})});case 5:response=_context.sent;_context.next=8;return response.json();case 8:data=_context.sent;setTranscriptTextArea(data.message);_context.next=15;break;case 12:_context.prev=12;_context.t0=_context[\"catch\"](2);console.log(_context.t0);case 15:case\"end\":return _context.stop();}},_callee,null,[[2,12]]);}));return function handleSendingToAI(){return _ref.apply(this,arguments);};}();var handleTranscriptTextAreaChange=function handleTranscriptTextAreaChange(event){setTranscriptTextArea(event.target.value);};return/*#__PURE__*/_jsxs(_Fragment,{children:[/*#__PURE__*/_jsx(\"button\",{onClick:handleStartCapture,children:\"Start audio capture\"}),/*#__PURE__*/_jsx(\"button\",{onClick:handleSendingToAI,children:\"Send to AI\"}),/*#__PURE__*/_jsx(\"textarea\",{ref:transcriptTextAreaRef,value:transcriptTextArea,onChange:handleTranscriptTextAreaChange,placeholder:\"The transcript will appear here\"})]});}export default AudioRetrieval;","map":{"version":3,"names":["React","useState","useEffect","useRef","jsx","_jsx","Fragment","_Fragment","jsxs","_jsxs","AudioRetrieval","_useState","_useState2","_slicedToArray","transcriptTextArea","setTranscriptTextArea","transcriptTextAreaRef","handleStartCapture","chrome","tabCapture","capture","audio","stream","audioContext","AudioContext","mediaStreamSource","createMediaStreamSource","connect","destination","SpeechRecognition","window","speechRecognition","webkitSpeechRecognition","recognition","continuous","interimResults","lang","listening","start","onresult","event","eventText","i","results","length","transcript","current","value","handleSendingToAI","_ref","_asyncToGenerator","_regeneratorRuntime","mark","_callee","prompt","response","data","wrap","_callee$","_context","prev","next","console","log","fetch","method","headers","body","JSON","stringify","sent","json","message","t0","stop","apply","arguments","handleTranscriptTextAreaChange","target","children","onClick","ref","onChange","placeholder"],"sources":["C:/Users/farha/OneDrive/Desktop/sak-productivity-suite/client/src/AudioRetrieval.js"],"sourcesContent":["/*global chrome*/\r\nimport React, {useState, useEffect, useRef} from \"react\";\r\n\r\nfunction AudioRetrieval() {\r\n\t\r\n\tconst [transcriptTextArea, setTranscriptTextArea] = useState(\"\");\r\n\tconst transcriptTextAreaRef = useRef(null);\r\n\t\r\n\tconst handleStartCapture = () => {\r\n\t\t\r\n\t\tchrome.tabCapture.capture({audio: true}, function(stream) {\r\n\t\t\t\r\n\t\t\tconst audioContext = new AudioContext();\r\n\r\n\t\t\tconst mediaStreamSource = audioContext.createMediaStreamSource(stream);\r\n\t\t\tmediaStreamSource.connect(audioContext.destination);\r\n\r\n\t\t\t// Set up the speech recognition object\r\n\t\t\tconst SpeechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\r\n\t\t\tconst recognition = new SpeechRecognition();\r\n\t\t\t\r\n\t\t\trecognition.continuous = true;\r\n\t\t\trecognition.interimResults = true;\r\n\t\t\trecognition.lang = 'en-US';\r\n\t\t\trecognition.listening = true;\r\n\t\t\t\r\n\t\t\trecognition.start();\r\n\r\n\t\t\t// Process the speech recognition results\r\n\t\t\trecognition.onresult = function(event) {\r\n\t\t\t\tlet eventText = \"\";\r\n\t\t\t\tfor (let i = 0; i < event.results.length; i++) {\r\n\t\t\t\t\teventText += event.results[i][0].transcript;\r\n\t\t\t\t}\r\n\t\t\t\t// console.log(eventText);\r\n\t\t\t\ttranscriptTextAreaRef.current.value = eventText;\r\n\t\t\t}\r\n\t\t\t\t\t\t\t\t\r\n\t\t});\r\n\t\t\r\n\t};\r\n\t\r\n\tconst handleSendingToAI = async() => {\r\n\t\tconst prompt = \"This is a question asked by a person: \"\r\n\t\t+ \" Answer in a sentence or two. Do not be verbose: \" + transcriptTextAreaRef.current.value;\r\n\t\tconsole.log(prompt);\r\n\t\t\r\n\t\ttry {\r\n\t\t\tconst response = await fetch(\"https://sak-productivity-suite.herokuapp.com/use-chatgpt\", {\r\n\t\t\t\tmethod: \"POST\",\r\n\t\t\t\theaders: {\r\n\t\t\t\t\t\"Content-Type\": \"application/json\"\r\n\t\t\t\t},\r\n\t\t\t\tbody: JSON.stringify({\r\n\t\t\t\t\tprompt: prompt\r\n\t\t\t\t})\r\n\t\t\t});\r\n\t\t\t\r\n\t\t\tconst data = await response.json();\t\r\n\t\t\tsetTranscriptTextArea(data.message);\t\t\t\r\n\r\n\t\t}catch(error){\r\n\t\t\tconsole.log(error);\r\n\t\t}\r\n\r\n\t};\r\n\t\r\n\t\t\r\n\tconst handleTranscriptTextAreaChange = (event) => {\r\n\t\tsetTranscriptTextArea(event.target.value);\r\n\t};\r\n\t\r\n\treturn (\r\n\t\t<>\r\n\t\t<button onClick={handleStartCapture}>\r\n\t\t\tStart audio capture\r\n\t\t</button>\r\n\t\t<button onClick={handleSendingToAI}>\r\n\t\t\tSend to AI\r\n\t\t</button>\r\n\t\t<textarea ref={transcriptTextAreaRef} value={transcriptTextArea} onChange={handleTranscriptTextAreaChange} placeholder=\"The transcript will appear here\"></textarea>\r\n\t\t</>\r\n\t);\r\n\r\n}\r\nexport default AudioRetrieval;"],"mappings":"ycAAA,iBACA,MAAO,CAAAA,KAAK,EAAGC,QAAQ,CAAEC,SAAS,CAAEC,MAAM,KAAO,OAAO,CAAC,OAAAC,GAAA,IAAAC,IAAA,gCAAAC,QAAA,IAAAC,SAAA,gCAAAC,IAAA,IAAAC,KAAA,yBAEzD,QAAS,CAAAC,cAAcA,CAAA,CAAG,CAEzB,IAAAC,SAAA,CAAoDV,QAAQ,CAAC,EAAE,CAAC,CAAAW,UAAA,CAAAC,cAAA,CAAAF,SAAA,IAAzDG,kBAAkB,CAAAF,UAAA,IAAEG,qBAAqB,CAAAH,UAAA,IAChD,GAAM,CAAAI,qBAAqB,CAAGb,MAAM,CAAC,IAAI,CAAC,CAE1C,GAAM,CAAAc,kBAAkB,CAAG,QAArB,CAAAA,kBAAkBA,CAAA,CAAS,CAEhCC,MAAM,CAACC,UAAU,CAACC,OAAO,CAAC,CAACC,KAAK,CAAE,IAAI,CAAC,CAAE,SAASC,MAAM,CAAE,CAEzD,GAAM,CAAAC,YAAY,CAAG,GAAI,CAAAC,YAAY,EAAE,CAEvC,GAAM,CAAAC,iBAAiB,CAAGF,YAAY,CAACG,uBAAuB,CAACJ,MAAM,CAAC,CACtEG,iBAAiB,CAACE,OAAO,CAACJ,YAAY,CAACK,WAAW,CAAC,CAEnD;AACA,GAAM,CAAAC,iBAAiB,CAAGC,MAAM,CAACC,iBAAiB,EAAID,MAAM,CAACE,uBAAuB,CACpF,GAAM,CAAAC,WAAW,CAAG,GAAI,CAAAJ,iBAAiB,EAAE,CAE3CI,WAAW,CAACC,UAAU,CAAG,IAAI,CAC7BD,WAAW,CAACE,cAAc,CAAG,IAAI,CACjCF,WAAW,CAACG,IAAI,CAAG,OAAO,CAC1BH,WAAW,CAACI,SAAS,CAAG,IAAI,CAE5BJ,WAAW,CAACK,KAAK,EAAE,CAEnB;AACAL,WAAW,CAACM,QAAQ,CAAG,SAASC,KAAK,CAAE,CACtC,GAAI,CAAAC,SAAS,CAAG,EAAE,CAClB,IAAK,GAAI,CAAAC,CAAC,CAAG,CAAC,CAAEA,CAAC,CAAGF,KAAK,CAACG,OAAO,CAACC,MAAM,CAAEF,CAAC,EAAE,CAAE,CAC9CD,SAAS,EAAID,KAAK,CAACG,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,CAAC,CAACG,UAAU,CAC5C,CACA;AACA7B,qBAAqB,CAAC8B,OAAO,CAACC,KAAK,CAAGN,SAAS,CAChD,CAAC,CAEF,CAAC,CAAC,CAEH,CAAC,CAED,GAAM,CAAAO,iBAAiB,6BAAAC,IAAA,CAAAC,iBAAA,cAAAC,mBAAA,GAAAC,IAAA,CAAG,SAAAC,QAAA,MAAAC,MAAA,CAAAC,QAAA,CAAAC,IAAA,QAAAL,mBAAA,GAAAM,IAAA,UAAAC,SAAAC,QAAA,iBAAAA,QAAA,CAAAC,IAAA,CAAAD,QAAA,CAAAE,IAAA,SACnBP,MAAM,CAAG,wCAAwC,CACrD,mDAAmD,CAAGtC,qBAAqB,CAAC8B,OAAO,CAACC,KAAK,CAC3Fe,OAAO,CAACC,GAAG,CAACT,MAAM,CAAC,CAACK,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA,SAGI,CAAAG,KAAK,CAAC,0DAA0D,CAAE,CACxFC,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACR,cAAc,CAAE,kBACjB,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAAC,CACpBf,MAAM,CAAEA,MACT,CAAC,CACF,CAAC,CAAC,QARIC,QAAQ,CAAAI,QAAA,CAAAW,IAAA,CAAAX,QAAA,CAAAE,IAAA,SAUK,CAAAN,QAAQ,CAACgB,IAAI,EAAE,QAA5Bf,IAAI,CAAAG,QAAA,CAAAW,IAAA,CACVvD,qBAAqB,CAACyC,IAAI,CAACgB,OAAO,CAAC,CAACb,QAAA,CAAAE,IAAA,kBAAAF,QAAA,CAAAC,IAAA,IAAAD,QAAA,CAAAc,EAAA,CAAAd,QAAA,aAGpCG,OAAO,CAACC,GAAG,CAAAJ,QAAA,CAAAc,EAAA,CAAO,CAAC,yBAAAd,QAAA,CAAAe,IAAA,MAAArB,OAAA,iBAGpB,kBAvBK,CAAAL,iBAAiBA,CAAA,SAAAC,IAAA,CAAA0B,KAAA,MAAAC,SAAA,OAuBtB,CAGD,GAAM,CAAAC,8BAA8B,CAAG,QAAjC,CAAAA,8BAA8BA,CAAIrC,KAAK,CAAK,CACjDzB,qBAAqB,CAACyB,KAAK,CAACsC,MAAM,CAAC/B,KAAK,CAAC,CAC1C,CAAC,CAED,mBACCtC,KAAA,CAAAF,SAAA,EAAAwE,QAAA,eACA1E,IAAA,WAAQ2E,OAAO,CAAE/D,kBAAmB,CAAA8D,QAAA,CAAC,qBAErC,EAAS,cACT1E,IAAA,WAAQ2E,OAAO,CAAEhC,iBAAkB,CAAA+B,QAAA,CAAC,YAEpC,EAAS,cACT1E,IAAA,aAAU4E,GAAG,CAAEjE,qBAAsB,CAAC+B,KAAK,CAAEjC,kBAAmB,CAACoE,QAAQ,CAAEL,8BAA+B,CAACM,WAAW,CAAC,iCAAiC,EAAY,GACjK,CAGL,CACA,cAAe,CAAAzE,cAAc"},"metadata":{},"sourceType":"module","externalDependencies":[]}